{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUC-Rio \n",
    "## Departamento de Engenharia Elétrica\n",
    "## Trabalho 2 - Previsão de séries temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, lag = 1, test_split = 0.1, normalize = False, category = 'binary'):\n",
    "    \n",
    "    global _min\n",
    "    global _max\n",
    "    \n",
    "    \n",
    "    data_values = data.values\n",
    "    \n",
    "    if 0 < test_split < 1.0:\n",
    "        l = data_values.shape[0]\n",
    "        train_values = data_values[:-int(test_split*l),0].reshape(-1,1)\n",
    "        test_values = data_values[-int(test_split*l):,0].reshape(-1,1)\n",
    "        train_idx = data_values[:-int(test_split*l),1].reshape(-1,1)\n",
    "        test_idx = data_values[-int(test_split*l):,1].reshape(-1,1)\n",
    "        \n",
    "    elif test_split > 1 and type(test_split) is int:\n",
    "\n",
    "        train_values = data_values[:-test_split,0].reshape(-1,1)\n",
    "        test_values = data_values[-test_split:,0].reshape(-1,1)\n",
    "        train_idx = data_values[:-test_split,1].reshape(-1,1)\n",
    "        test_idx = data_values[-test_split:,1].reshape(-1,1)\n",
    "        \n",
    "    else:\n",
    "        print('Test split not understood. Test split should be float between 0 and 1 or integer for index')\n",
    "    \n",
    "    assert test_values.shape[0] >= (lag)\n",
    "    \n",
    "    _min = np.min(train_values)\n",
    "    _max = np.max(train_values)\n",
    "    \n",
    "    if normalize:\n",
    "        \n",
    "        test_values = (test_values - _min)/(_max - _min)\n",
    "        train_values = (train_values - _min)/(_max - _min)\n",
    "        \n",
    "    train_data = np.zeros((train_values.shape[0] - (lag + 1), lag + 2))\n",
    "    test_data = np.zeros((test_values.shape[0], lag + 2))\n",
    "    \n",
    "    \n",
    "    all_data = np.vstack((train_values,test_values))\n",
    "    all_idx = np.vstack((train_idx,test_idx))\n",
    "\n",
    "    new_data = np.zeros((train_values.shape[0] - (lag + 1) + test_values.shape[0],lag + 2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(lag + 2):\n",
    "        new_data[:,i] = all_data[i:new_data.shape[0]+i,0]\n",
    "        \n",
    "\n",
    "    \n",
    "    if category == 'binary':\n",
    "        binary_rep = [np.binary_repr(z,width=4) for z in all_idx.astype('int').reshape(-1,)]\n",
    "        t0 = np.array([int(v) for s in binary_rep for v in s[0]])\n",
    "        t1 = np.array([int(v) for s in binary_rep for v in s[1]])\n",
    "        t2 = np.array([int(v) for s in binary_rep for v in s[2]])\n",
    "        t3 = np.array([int(v) for s in binary_rep for v in s[3]])\n",
    "        t = np.vstack((t0,t1,t2,t3)).T\n",
    "        t = t[-new_data.shape[0]:,:]\n",
    "        temp_idx = [f'month_{i}' for i in range(4)]\n",
    "        \n",
    "    elif category == '1toN':\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        t = (all_idx - np.min(train_idx))/(np.max(train_idx) - np.min(train_idx))\n",
    "        t = t.reshape(-1,1)\n",
    "        t = t[-new_data.shape[0]:,:]\n",
    "        temp_idx = ['month']\n",
    "    \n",
    "    \n",
    "    new_data = np.hstack((t,new_data))\n",
    "    \n",
    "    train_data = new_data[:-test_values.shape[0],:]\n",
    "    test_data = new_data[-test_values.shape[0]:,:]\n",
    "    \n",
    "    \n",
    "    data_columns = [f'y(t{i})' if i < 0 else 'y(t)' if i == 0 else f'y(t+{i})' for i in range(-lag,2)] \n",
    "    temp_idx.extend(data_columns)\n",
    "    new_train_df = pd.DataFrame(train_data, columns=temp_idx)\n",
    "    new_test_df = pd.DataFrame(test_data, columns=temp_idx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return new_train_df, new_test_df\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('microclima2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = transform_data(raw_data,lag=12,test_split = 12,normalize=True,category='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = train.values\n",
    "\n",
    "x_train = train_values[:,:-1]\n",
    "y_train = train_values[:,-1]\n",
    "\n",
    "test_values = test.values\n",
    "x_test = test_values[:,:-1]\n",
    "y_test = test_values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_neurons = [4], hidden_activation = ['relu'], output_activation='softmax', lr = 0.05, n_input = 1, n_output = 1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_neurons[0], input_dim=n_input, activation='tanh'))\n",
    "    for i in range(1,len(hidden_neurons)):\n",
    "        model.add(Dense(hidden_neurons[i], input_dim=hidden_neurons[i-1], activation='tanh'))\n",
    "        \n",
    "\n",
    "    model.add(Dense(n_output, activation=output_activation))\n",
    "    # Compile model\n",
    "    opt = Adam(lr=lr)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=opt, metrics=['mean_absolute_error','mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(hidden_neurons = [10], output_activation='linear', n_input = x_train.shape[1], n_output = 1, lr = 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,y=y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_train)\n",
    "plt.plot(y_train)\n",
    "plt.plot(y_hat)\n",
    "plt.legend(['Original','Predicted'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 'One step-ahead'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test)\n",
    "plt.plot(y_hat)\n",
    "plt.legend(['Original','Predicted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_y_eval = y_test*(_max-_min) + _min\n",
    "orig_y_hat = y_hat*(_max-_min) + _min\n",
    "mae_error = mean_absolute_error(orig_y_eval, orig_y_hat)\n",
    "mse_error = mean_squared_error(orig_y_eval, orig_y_hat)\n",
    "\n",
    "print(f'Erro MSE = {round(mse_error,3)} \\nErro MAE = {round(mae_error,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Multi-step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpuc",
   "language": "python",
   "name": "nnpuc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
